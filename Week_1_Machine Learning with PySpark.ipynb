{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 1\n\n# Import the PySpark module\nfrom pyspark.sql import SparkSession\n\n# Create SparkSession object\nspark = SparkSession.builder \\\n                    .master('local[*]') \\\n                    .appName('test') \\\n                    .getOrCreate()\n\n# What version of Spark?\nprint(spark.version)\n\n# Terminate the cluster\nspark.stop()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 2\n\n# Read data from CSV file\nflights = spark.read.csv('flights.csv',\n                         sep=',',\n                         header=True,\n                         inferSchema=True,\n                         nullValue='NA')\n\n# Get number of records\nprint(\"The data contain %d records.\" % flights.count())\n\n# View the first five records\nflights.show(5)\n\n# Check column data types\nflights.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 3\n\nfrom pyspark.sql.types import StructType, StructField, IntegerType, StringType\n\n# Specify column names and types\nschema = StructType([\n    StructField(\"id\", IntegerType()),\n    StructField(\"text\", StringType()),\n    StructField(\"label\", IntegerType())\n])\n\n# Load data from a delimited file\nsms = spark.read.csv('sms.csv', sep=';', header=False, schema=schema)\n\n# Print schema of DataFrame\nsms.printSchema()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}